{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Robot   num1    num2     num3     num4      num5       num6       num7  \\\n",
      "0      1      2       5        2        5         6          2          1   \n",
      "1      2   1747    1749     1751     1758      1765       1767       1772   \n",
      "2      3  65056  195168  1561344  7806720  31226880  187361280  749445120   \n",
      "3      4   2855    2860     2865     2870      2875       2880       2885   \n",
      "4      5  11440   57200   286000  1430000   7150000   35750000  178750000   \n",
      "5      1      4       9        5        4         8          6          6   \n",
      "6      2   1487    1491     1498     1503      1512       1514       1518   \n",
      "7      3  18850   18850   113100   452400    452400    1809600    3619200   \n",
      "8      4   8962    8967     8972     8977      8982       8987       8992   \n",
      "9      5   2870   14350    71750   358750   1793750    8968750   44843750   \n",
      "\n",
      "           num8          num9         num10  \n",
      "0  8.000000e+00  1.000000e+00  3.000000e+00  \n",
      "1  1.774000e+03  1.783000e+03  1.785000e+03  \n",
      "2  6.745006e+09  6.745006e+09  6.745006e+09  \n",
      "3  2.890000e+03  2.895000e+03  2.900000e+03  \n",
      "4  8.937500e+08  4.468750e+09  2.234375e+10  \n",
      "5  7.000000e+00  7.000000e+00  2.000000e+00  \n",
      "6  1.522000e+03  1.524000e+03  1.528000e+03  \n",
      "7  3.619200e+06  7.238400e+06  5.066880e+07  \n",
      "8  8.997000e+03  9.002000e+03  9.007000e+03  \n",
      "9  2.242188e+08  1.121094e+09  5.605469e+09  \n",
      "(500000, 11)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statistics\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"Classification of Robots from their conversation sequence.csv\")\n",
    "# Display the first 10 rows of the dataset\n",
    "print(df.head(10))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "X = df[['num1', 'num2', 'num3', 'num4', 'num5', 'num6', 'num7', 'num8', 'num9', 'num10']]  # Features\n",
    "y = df['Robot']  # Labels\n",
    "\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = Normalizer()\n",
    "#X_train_normalized = scaler.fit_transform(X_train)\n",
    "#X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# MODEL_Trainer = SVC(C=10000, kernel='rbf')\n",
    "\n",
    "# This takes too long to run\n",
    "# MODEL_Trainer.fit(X_train_normalized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the trained model on our test data\n",
    "\n",
    "# This takes too long to run\n",
    "# y_pred = MODEL_Trainer.predict(X_test_normalized)\n",
    "\n",
    "# Print the Classification Report and Confusion Matrix\n",
    "# print(\"Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='viridis', xticklabels=['1', '2', '3', '4', '5'], yticklabels=['1', '2', '3', '4', '5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "40000\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "chunk_number = 10\n",
    "chunk_size = math.ceil(len(y_train) / chunk_number)\n",
    "x_chunked = {}\n",
    "y_chunked = {}\n",
    "m = 0\n",
    "\n",
    "for i in range(0, len(y_train), chunk_size):\n",
    "    if m == chunk_number-1:\n",
    "        chunk_size = len(X_train) - m * chunk_size\n",
    "    x_chunked[str(\"chunk\"+str(m))] = X_train[i:i+chunk_size]\n",
    "    y_chunked[str(\"chunk\"+str(m))] = y_train[i:i+chunk_size]\n",
    "    print(chunk_size)\n",
    "    m = m + 1\n",
    "\n",
    "for i in range(chunk_number):\n",
    "    Data_M = x_chunked[str(\"chunk\"+str(i))].copy()\n",
    "    Data_labels_M = y_chunked[str(\"chunk\"+str(i))].copy()\n",
    "    SVMC = Pipeline(steps=[('Normal', Normalizer()), ('SVMC', SVC(C=1000000, kernel='rbf'))])\n",
    "    SVMC.fit(Data_M, Data_labels_M)\n",
    "    pickle.dump(SVMC, open(str(\"SV_Models\\\\SVMC\"+str(i)+\".pkl\"), 'wb'))\n",
    "    print(i)\n",
    "\n",
    "OUT_SVMC={}\n",
    "store = [[0 for col in range(chunk_number)] for row in range(len(y_test))]\n",
    "Lables_SVMC_predicted=[[0 for col in range(1)] for row in range(len(y_test))]\n",
    "\n",
    "for i in range(0,chunk_number):\n",
    "    SVMC1 = pickle.load(open(str('SV_Models\\\\SVMC' + str(i) + '.pkl'), 'rb'))\n",
    "    OUT_SVMC[str(\"chunk\"+str(i))] = SVMC1.predict(X_test)\n",
    "    print(i)\n",
    "\n",
    "for j in range(0,len(X_test)):\n",
    "    for i in range(0,chunk_number):\n",
    "        store[j][i]=OUT_SVMC[str(\"chunk\"+str(i))][j]\n",
    "        Lables_SVMC_predicted[j]=statistics.max(store[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
